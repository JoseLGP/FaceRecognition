{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isdir\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot\n",
    "from numpy import savez_compressed\n",
    "from numpy import asarray\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "from keras.models import load_model\n",
    "from numpy import load\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from numpy import linalg as la\n",
    "from matplotlib import pyplot\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# face detection for the 5 Celebrity Faces Dataset\n",
    " \n",
    "# extract a single face from a given photograph\n",
    "def extract_face(filename, required_size=(160, 160)):\n",
    "\t# load image from file\n",
    "\timage = Image.open(filename)\n",
    "\t# convert to RGB, if needed\n",
    "\timage = image.convert('RGB')\n",
    "\t# convert to array\n",
    "\tpixels = asarray(image)\n",
    "\t# create the detector, using default weights\n",
    "\tdetector = MTCNN()\n",
    "\t# detect faces in the image\n",
    "\tresults = detector.detect_faces(pixels)\n",
    "\t# extract the bounding box from the first face\n",
    "\tx1, y1, width, height = results[0]['box']\n",
    "\t# bug fix\n",
    "\tx1, y1 = abs(x1), abs(y1)\n",
    "\tx2, y2 = x1 + width, y1 + height\n",
    "\t# extract the face\n",
    "\tface = pixels[y1:y2, x1:x2]\n",
    "\t# resize pixels to the model size\n",
    "\timage = Image.fromarray(face)\n",
    "\timage = image.resize(required_size)\n",
    "\tface_array = asarray(image)\n",
    "\treturn face_array\n",
    " \n",
    "# load images and extract faces for all images in a directory\n",
    "def load_faces(directory):\n",
    "\tfaces = list()\n",
    "\t# enumerate files\n",
    "\tfor filename in listdir(directory):\n",
    "\t\t# path\n",
    "\t\tpath = directory + filename\n",
    "\t\t# get face\n",
    "\t\tface = extract_face(path)\n",
    "\t\t# store\n",
    "\t\tfaces.append(face)\n",
    "\treturn faces\n",
    " \n",
    "# load a dataset that contains one subdir for each class that in turn contains images\n",
    "def load_dataset(directory):\n",
    "\tX, y = list(), list()\n",
    "\t# enumerate folders, on per class\n",
    "\tfor subdir in listdir(directory):\n",
    "\t\t# path\n",
    "\t\tpath = directory + subdir + '/'\n",
    "\t\t# skip any files that might be in the dir\n",
    "\t\tif not isdir(path):\n",
    "\t\t\tcontinue\n",
    "\t\t# load all faces in the subdirectory\n",
    "\t\tfaces = load_faces(path)\n",
    "\t\t# create labels\n",
    "\t\tlabels = [subdir for _ in range(len(faces))]\n",
    "\t\t# summarize progress\n",
    "\t\tprint('>loaded %d examples for class: %s' % (len(faces), subdir))\n",
    "\t\t# store\n",
    "\t\tX.extend(faces)\n",
    "\t\ty.extend(labels)\n",
    "\treturn asarray(X), asarray(y)\n",
    " \n",
    "# load train dataset\n",
    "trainX, trainy = load_dataset('data/train/')\n",
    "print(trainX.shape, trainy.shape)\n",
    "# load test dataset\n",
    "testX, testy = load_dataset('data/val/')\n",
    "# save arrays to one file in compressed format\n",
    "savez_compressed('5-celebrity-faces-dataset.npz', trainX, trainy, testX, testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded:  (93, 160, 160, 3) (93,) (25, 160, 160, 3) (25,)\n"
     ]
    }
   ],
   "source": [
    "# load the face dataset\n",
    "data = load('notebooks/5-celebrity-faces-dataset.npz')\n",
    "trainX, trainy, testX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\n",
    "print('Loaded: ', trainX.shape, trainy.shape, testX.shape, testy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\lenovo\\Anaconda3\\envs\\PythonCPU\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Loaded Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\Anaconda3\\envs\\PythonCPU\\lib\\site-packages\\keras\\engine\\saving.py:341: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "# load the facenet model\n",
    "model = load_model('../keras-facenet/model/facenet_keras.h5')\n",
    "print('Loaded Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded:  (91, 160, 160, 3) (91,) (25, 160, 160, 3) (25,)\n",
      "Loaded Model\n",
      "(91, 128)\n",
      "(25, 128)\n"
     ]
    }
   ],
   "source": [
    "# calculate a face embedding for each face in the dataset using facenet\n",
    "from numpy import load\n",
    "from numpy import expand_dims\n",
    "from numpy import asarray\n",
    "from numpy import savez_compressed\n",
    "from keras.models import load_model\n",
    " \n",
    "# get the face embedding for one face\n",
    "def get_embedding(model, face_pixels):\n",
    "\t# scale pixel values\n",
    "\tface_pixels = face_pixels.astype('float32')\n",
    "\t# standardize pixel values across channels (global)\n",
    "\tmean, std = face_pixels.mean(), face_pixels.std()\n",
    "\tface_pixels = (face_pixels - mean) / std\n",
    "\t# transform face into one sample\n",
    "\tsamples = expand_dims(face_pixels, axis=0)\n",
    "\t# make prediction to get embedding\n",
    "\tyhat = model.predict(samples)\n",
    "\treturn yhat[0]\n",
    " \n",
    "# load the face dataset\n",
    "data = load('5-celebrity-faces-dataset.npz')\n",
    "trainX, trainy, testX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\n",
    "print('Loaded: ', trainX.shape, trainy.shape, testX.shape, testy.shape)\n",
    "\n",
    "# load the facenet model\n",
    "model = load_model('keras-facenet/model/facenet_keras.h5')\n",
    "print('Loaded Model')\n",
    "\n",
    "# convert each face in the train set to an embedding\n",
    "newTrainX = list()\n",
    "for face_pixels in trainX:\n",
    "\tembedding = get_embedding(model, face_pixels)\n",
    "\tnewTrainX.append(embedding)\n",
    "newTrainX = asarray(newTrainX)\n",
    "print(newTrainX.shape)\n",
    "\n",
    "# convert each face in the test set to an embedding\n",
    "newTestX = list()\n",
    "for face_pixels in testX:\n",
    "\tembedding = get_embedding(model, face_pixels)\n",
    "\tnewTestX.append(embedding)\n",
    "newTestX = asarray(newTestX)\n",
    "print(newTestX.shape)\n",
    "\n",
    "# save arrays to one file in compressed format\n",
    "savez_compressed('5-celebrity-faces-embeddings.npz', newTrainX, trainy, newTestX, testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: train=91, test=25\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "data = load('5-celebrity-faces-embeddings.npz')\n",
    "trainX, trainy, testX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\n",
    "print('Dataset: train=%d, test=%d' % (trainX.shape[0], testX.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalize input vectors\n",
    "in_encoder = Normalizer(norm='l2')\n",
    "trainX = in_encoder.transform(trainX)\n",
    "testX = in_encoder.transform(testX)\n",
    "\n",
    "# label encode targets\n",
    "out_encoder = LabelEncoder()\n",
    "out_encoder.fit(trainy)\n",
    "trainy = out_encoder.transform(trainy)\n",
    "testy = out_encoder.transform(testy)\n",
    "\n",
    "trainy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifying identity\n",
    "\n",
    "faces = trainX\n",
    "embedding = trainX.flatten()\n",
    "D = []\n",
    "pairs = []\n",
    "d = 0.7\n",
    "Psame = []\n",
    "Pdiff = []\n",
    "TA = []\n",
    "FA = []\n",
    "\n",
    "# Selecting all possible pairs and computing L2-distance\n",
    "for i in range(len(faces)):\n",
    "    for j in range(len(faces)):\n",
    "        selection = np.random.choice(embedding, size=128, replace=False)\n",
    "        l2 = la.norm(selection[0] - selection[1])**2\n",
    "        pairs.append(selection)\n",
    "        D.append(l2)\n",
    "        if l2 < d:\n",
    "            Psame.append(selection)\n",
    "        else:\n",
    "            Pdiff.append(selection)\n",
    "                \n",
    "# Plotting each pair in Psame and Pdiff\n",
    "\n",
    "# Computing Metrics\n",
    "\n",
    "# True Accepts\n",
    "for s in range(len(Psame)):\n",
    "         if D[s] <= d:\n",
    "                TA.append(Psame[s])\n",
    "# False Accepts\n",
    "for m in range(len(Pdiff)):\n",
    "         if D[m] <= d:\n",
    "                FA.append(Pdiff[m])  \n",
    "                \n",
    "# VAL and FAR rates\n",
    "Psame_a = np.array(Psame)\n",
    "Pdiff_a = np.array(Pdiff)\n",
    "TA_a = np.array(TA)\n",
    "FA_a = np.array(FA)\n",
    "Ps, Pd = np.absolute(Psame_a), np.absolute(Pdiff_a)\n",
    "true, false = np.absolute(TA_a), np.absolute(FA_a)\n",
    "\n",
    "VAL = true/Ps\n",
    "FAR = false/Pd\n",
    "\n",
    "# Plotting VAL vs FAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
